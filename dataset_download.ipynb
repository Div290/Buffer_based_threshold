{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oUqyuU_8HuU8"
      },
      "source": [
        "# For IMDb dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "DrFzfMaKHivV"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading IMDb dataset...\n",
            "Extracting IMDb dataset...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_562585/2482194846.py:20: DeprecationWarning: Python 3.14 will, by default, filter extracted tar archives and reject files or modify their metadata. Use the filter argument to control this behavior.\n",
            "  tar_ref.extractall(target_dir)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "IMDb dataset downloaded and extracted!\n",
            "Saved imdb_data/train.csv\n",
            "Saved imdb_data/test.csv\n",
            "IMDb dataset successfully converted to CSV format!\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import urllib.request\n",
        "import zipfile\n",
        "import pandas as pd\n",
        "\n",
        "# Define URLs and target directory\n",
        "imdb_url = \"https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\"\n",
        "target_dir = \"imdb_data\"\n",
        "\n",
        "def download_and_extract(url, target_dir):\n",
        "    os.makedirs(target_dir, exist_ok=True)\n",
        "    tar_path = os.path.join(target_dir, \"aclImdb_v1.tar.gz\")\n",
        "\n",
        "    print(\"Downloading IMDb dataset...\")\n",
        "    urllib.request.urlretrieve(url, tar_path)\n",
        "\n",
        "    print(\"Extracting IMDb dataset...\")\n",
        "    import tarfile\n",
        "    with tarfile.open(tar_path, \"r:gz\") as tar_ref:\n",
        "        tar_ref.extractall(target_dir)\n",
        "\n",
        "    print(\"IMDb dataset downloaded and extracted!\")\n",
        "\n",
        "# Function to convert IMDB reviews to CSV\n",
        "def convert_imdb_to_csv(input_dir, output_csv):\n",
        "    data = []\n",
        "    for label in [\"pos\", \"neg\"]:\n",
        "        folder = os.path.join(input_dir, label)\n",
        "        for file in os.listdir(folder):\n",
        "            with open(os.path.join(folder, file), \"r\", encoding=\"utf-8\") as f:\n",
        "                review = f.read().strip()\n",
        "                data.append([review, 1 if label == \"pos\" else 0])\n",
        "\n",
        "    df = pd.DataFrame(data, columns=[\"reviews\", \"labels\"])\n",
        "    df.to_csv(output_csv, index=False)\n",
        "    print(f\"Saved {output_csv}\")\n",
        "\n",
        "# Download and extract the dataset\n",
        "download_and_extract(imdb_url, target_dir)\n",
        "\n",
        "# Convert train and test sets to CSV\n",
        "convert_imdb_to_csv(os.path.join(target_dir, \"aclImdb/train\"), os.path.join(target_dir, \"train.csv\"))\n",
        "convert_imdb_to_csv(os.path.join(target_dir, \"aclImdb/test\"), os.path.join(target_dir, \"test.csv\"))\n",
        "\n",
        "print(\"IMDb dataset successfully converted to CSV format!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6v8nNcMpIAgr"
      },
      "source": [
        "# For QNLI dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "OyLRFNXcH_fE"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading QNLI dataset...\n",
            "Download complete!\n",
            "Extracting QNLI dataset...\n",
            "Extraction complete!\n",
            "Extracted files: ['QNLI.zip', 'QNLI']\n",
            "No TSV files found! Check extraction path.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import urllib.request\n",
        "import zipfile\n",
        "\n",
        "# Define URLs and target directory\n",
        "qnli_url = \"https://dl.fbaipublicfiles.com/glue/data/QNLI.zip\"\n",
        "target_dir = \"qnli_data\"\n",
        "\n",
        "# Create target directory if it doesn't exist\n",
        "os.makedirs(target_dir, exist_ok=True)\n",
        "zip_path = os.path.join(target_dir, \"QNLI.zip\")\n",
        "\n",
        "# Download the QNLI dataset\n",
        "print(\"Downloading QNLI dataset...\")\n",
        "urllib.request.urlretrieve(qnli_url, zip_path)\n",
        "print(\"Download complete!\")\n",
        "\n",
        "# Extract the dataset\n",
        "print(\"Extracting QNLI dataset...\")\n",
        "with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n",
        "    zip_ref.extractall(target_dir)\n",
        "print(\"Extraction complete!\")\n",
        "\n",
        "# List extracted files\n",
        "extracted_files = os.listdir(target_dir)\n",
        "print(f\"Extracted files: {extracted_files}\")\n",
        "\n",
        "# Ensure TSV files are saved\n",
        "tsv_files = [f for f in extracted_files if f.endswith(\".tsv\")]\n",
        "if tsv_files:\n",
        "    print(\"TSV files successfully saved in:\", target_dir)\n",
        "else:\n",
        "    print(\"No TSV files found! Check extraction path.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bmdV27U4Hokp"
      },
      "source": [
        "# For SST-2 Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "lLYnnZkYHnPH"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SST-2 dataset downloaded and extracted!\n",
            "Converted sst2_data/SST-2/train.tsv to sst2_data/train.csv\n",
            "Converted sst2_data/SST-2/dev.tsv to sst2_data/dev.csv\n",
            "Converted sst2_data/SST-2/test.tsv to sst2_data/test.csv\n",
            "SST-2 dataset successfully converted to CSV format!\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import urllib.request\n",
        "import zipfile\n",
        "import pandas as pd\n",
        "\n",
        "# Define URLs and target directory\n",
        "sst2_url = \"https://dl.fbaipublicfiles.com/glue/data/SST-2.zip\"\n",
        "target_dir = \"sst2_data\"\n",
        "\n",
        "# Download the SST-2 dataset\n",
        "os.makedirs(target_dir, exist_ok=True)\n",
        "zip_path = os.path.join(target_dir, \"SST-2.zip\")\n",
        "urllib.request.urlretrieve(sst2_url, zip_path)\n",
        "\n",
        "# Extract the dataset\n",
        "with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n",
        "    zip_ref.extractall(target_dir)\n",
        "\n",
        "print(\"SST-2 dataset downloaded and extracted!\")\n",
        "\n",
        "# Convert TSV to CSV\n",
        "def convert_tsv_to_csv(tsv_path, csv_path):\n",
        "    df = pd.read_csv(tsv_path, delimiter=\"\\t\")\n",
        "    df.columns = [\"reviews\", \"labels\"]  # Rename columns\n",
        "    df.to_csv(csv_path, index=False)\n",
        "    print(f\"Converted {tsv_path} to {csv_path}\")\n",
        "\n",
        "# Convert train, dev, and test sets\n",
        "convert_tsv_to_csv(os.path.join(target_dir, \"SST-2/train.tsv\"), os.path.join(target_dir, \"train.csv\"))\n",
        "convert_tsv_to_csv(os.path.join(target_dir, \"SST-2/dev.tsv\"), os.path.join(target_dir, \"dev.csv\"))\n",
        "convert_tsv_to_csv(os.path.join(target_dir, \"SST-2/test.tsv\"), os.path.join(target_dir, \"test.csv\"))\n",
        "\n",
        "print(\"SST-2 dataset successfully converted to CSV format!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
